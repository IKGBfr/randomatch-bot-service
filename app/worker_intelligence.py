"""
Worker Intelligence - Traite les messages avec intelligence conversationnelle

‚úÖ VERSION 3.0 - Anti-Double R√©ponse Robuste
- Lock Redis distribu√© (multi-instance safe)
- Monitoring continu (r√©flexion + frappe)
- Annulation si nouveaux messages d√©tect√©s
"""

import asyncio
import json
import logging
from datetime import datetime
from app.supabase_client import SupabaseClient
import redis.asyncio as redis
from openai import OpenAI

from app.config import settings
from app.pre_processing import PreProcessor
from app.analysis import message_analyzer
from app.utils.timing import timing_engine
from app.exit_manager import ExitManager
from app.prompt_builder import prompt_builder
from app.response_cache import ResponseCache

# üÜï NOUVEAUX IMPORTS
from app.conversation_lock import ConversationLock
from app.continuous_monitor import ContinuousMonitor
from app.unanswered_detector import UnansweredDetector  # üÜï NOUVEAU
from app.availability_checker import get_availability_checker  # ‚è∞ V√âRIF HORAIRES

logging.basicConfig(
    level=getattr(logging, settings.log_level),
    format='%(asctime)s - %(levelname)s - %(name)s - %(message)s'
)
logger = logging.getLogger(__name__)


class WorkerIntelligence:
    """Worker intelligent avec lock distribu√© + monitoring continu"""
    
    def __init__(self):
        self.supabase: SupabaseClient = None
        self.redis_client = None
        self.openai_client = None
        self.pre_processor = None
        self.exit_manager = ExitManager(
            min_messages=15,
            max_messages=30,
            exit_chance=0.05
        )
        
        # üÜï LOCK REDIS DISTRIBU√â (remplace asyncio.Lock)
        self.conversation_lock: ConversationLock = None
        
        # üÜï MONITORING CONTINU (remplace MessageMonitor)
        self.continuous_monitor: ContinuousMonitor = None
        
        # Response cache (conserv√©)
        self.response_cache: ResponseCache = None
        
        # üÜï D√âTECTEUR MESSAGES SANS R√âPONSE
        self.unanswered_detector: UnansweredDetector = None
        
        # ‚è∞ V√âRIFICATEUR DISPONIBILIT√â
        self.availability_checker = None
    
    async def connect(self):
        """
        M√©thode unifi√©e pour connecter tous les services.
        Utilis√©e par scheduled_processor.
        """
        await self.connect_supabase()
        await self.connect_redis()
        self.connect_openai()
        
    async def connect_supabase(self):
        """Connexion Supabase custom client"""
        logger.info("üîå Connexion √† Supabase...")
        self.supabase = SupabaseClient()
        await self.supabase.connect()
        self.pre_processor = PreProcessor(self.supabase)
        
        # üÜï Initialiser continuous monitor
        self.continuous_monitor = ContinuousMonitor(self.supabase)
        
        # üÜï Initialiser unanswered detector
        self.unanswered_detector = UnansweredDetector()
        
        # ‚è∞ Initialiser availability checker
        self.availability_checker = await get_availability_checker()
        
        logger.info("‚úÖ Connect√© √† Supabase + Continuous Monitor + Unanswered Detector + Availability Checker")
        
    async def connect_redis(self):
        """Connexion Redis"""
        logger.info("üîå Connexion √† Redis...")
        self.redis_client = await redis.from_url(
            settings.redis_url,
            encoding="utf-8",
            decode_responses=True
        )
        
        # üÜï Initialiser conversation lock (Redis distribu√©)
        self.conversation_lock = ConversationLock(self.redis_client)
        
        # Response cache
        self.response_cache = ResponseCache(self.redis_client)
        
        logger.info("‚úÖ Connect√© √† Redis + Lock distribu√© + Cache")
    
    def connect_openai(self):
        """Connexion OpenRouter"""
        logger.info("üîå Connexion √† OpenRouter...")
        self.openai_client = OpenAI(
            base_url=settings.openrouter_base_url,
            api_key=settings.openrouter_api_key
        )
        logger.info("‚úÖ Connect√© √† OpenRouter")
    
    def build_prompt(
        self,
        bot_profile: dict,
        memory: dict,
        history: list,
        current_message: str,
        analysis: dict
    ) -> str:
        """Construit un prompt enrichi avec full context"""
        system_prompt = bot_profile.get('system_prompt', '')
        
        # M√©moire long-terme
        memory_context = f"""
M√âMOIRE DE CETTE PERSONNE:
- Nom: {memory.get('user_name', 'inconnu')}
- Niveau relation: {memory.get('relationship_level', 'stranger')}
- Trust score: {memory.get('trust_score', 0)}/100
- Ton conversation: {memory.get('conversation_tone', 'neutral')}
- Topics pr√©f√©r√©s: {', '.join(memory.get('preferred_topics', [])) or 'aucun'}
- Topics √† √©viter: {', '.join(memory.get('topics_to_avoid', [])) or 'aucun'}
"""
        
        # Historique (derniers 30 messages max pour prompt)
        history_context = "\n".join([
            f"{msg.get('profiles', {}).get('first_name', 'Inconnu')}: {msg['content']}"
            for msg in history[-30:]
        ])
        
        # Analysis
        analysis_context = f"""
ANALYSE DU MESSAGE:
- Urgence: {analysis['urgency']}/5
- Complexit√©: {analysis['complexity']}/5
- Ton √©motionnel: {analysis['emotional_tone']}
- Type: {analysis['message_type']}
"""
        
        # Instructions adaptatives
        instructions = "INSTRUCTIONS:\n"
        
        if analysis['urgency'] >= 4:
            instructions += "- R√©ponds rapidement et directement\n"
        
        if analysis['requires_multi_messages']:
            instructions += "- D√©coupe ta r√©ponse en 2-3 messages courts et naturels\n"
            instructions += "- S√©pare chaque message par ||| OU [MSG_BREAK] OU double saut de ligne\n"
            instructions += "- Exemple: 'Salut !|||Comment √ßa va ?|||Moi √ßa va bien'\n"
        else:
            instructions += "- Un seul message naturel suffit\n"
        
        if memory.get('trust_score', 0) >= 70:
            instructions += "- Relation √©tablie, sois plus authentique et intime\n"
        else:
            instructions += "- Relation naissante, reste naturel mais l√©ger\n"
        
        # Assembler
        full_prompt = f"""{system_prompt}

{memory_context}

HISTORIQUE CONVERSATION:
{history_context}

{analysis_context}

{instructions}

MESSAGE ACTUEL:
{current_message}

TA R√âPONSE:"""
        
        return full_prompt
    
    def generate_response(self, prompt: str, temperature: float = 0.8) -> str:
        """G√©n√®re une r√©ponse avec Grok"""
        try:
            response = self.openai_client.chat.completions.create(
                model=settings.openrouter_model,
                messages=[
                    {"role": "user", "content": prompt}
                ],
                temperature=temperature,
                max_tokens=500
            )
            
            return response.choices[0].message.content.strip()
            
        except Exception as e:
            logger.error(f"‚ùå Erreur g√©n√©ration: {e}")
            return "D√©sol√©, j'ai un petit bug technique üòÖ"
    
    async def activate_typing(self, bot_id: str, match_id: str):
        """Active l'indicateur de frappe"""
        try:
            await self.supabase.upsert('typing_events', {
                'user_id': bot_id,
                'match_id': match_id,
                'is_typing': True,
                'started_at': datetime.now()
            })
        except Exception as e:
            logger.error(f"‚ùå Erreur activate typing: {e}")
    
    async def deactivate_typing(self, bot_id: str, match_id: str):
        """D√©sactive l'indicateur de frappe"""
        try:
            await self.supabase.upsert('typing_events', {
                'user_id': bot_id,
                'match_id': match_id,
                'is_typing': False,
                'updated_at': datetime.now()
            })
        except Exception as e:
            logger.error(f"‚ùå Erreur deactivate typing: {e}")
    
    async def send_message(self, match_id: str, bot_id: str, content: str):
        """
        Envoie un message (avec interception [UNMATCH])
        
        Si le message contient [UNMATCH], le marqueur est retir√©,
        l'unmatch est d√©clench√©, et seul le message propre est envoy√©.
        """
        try:
            # üÜï INTERCEPTION [UNMATCH]
            from app.unmatch_handler import unmatch_handler
            
            clean_content, unmatch_triggered = await unmatch_handler.process_message_with_unmatch(
                content,
                match_id,
                bot_id
            )
            
            # Envoyer le message propre (sans [UNMATCH])
            await self.supabase.insert('messages', {
                'match_id': match_id,
                'sender_id': bot_id,
                'content': clean_content,
                'type': 'text',
                'status': 'sent'
            })
            
            if unmatch_triggered:
                logger.info(f"‚úÖ Message envoy√© + Unmatch d√©clench√©: {clean_content[:50]}...")
            else:
                logger.info(f"‚úÖ Message envoy√©: {clean_content[:50]}...")
            
        except Exception as e:
            logger.error(f"‚ùå Erreur envoi message: {e}")
            raise
    
    async def process_message(self, event_data: dict):
        """
        ‚úÖ VERSION 3.0 - Point d'entr√©e avec lock Redis distribu√©
        
        Garantit qu'un seul worker traite un match √† la fois,
        m√™me avec plusieurs instances Railway.
        """
        # Extraction match_id
        if event_data.get('type') == 'grouped':
            match_id = event_data['match_id']
        else:
            match_id = event_data['match_id']
        
        # ============================================
        # üÜï TENTATIVE D'ACQUISITION DU LOCK REDIS
        # ============================================
        
        logger.info(f"üîí Tentative acquisition lock Redis pour {match_id[:8]}...")
        
        lock_acquired = await self.conversation_lock.acquire(match_id, timeout=5)
        
        if not lock_acquired:
            logger.warning(
                f"‚è∏Ô∏è  Match {match_id[:8]} d√©j√† en traitement par un autre worker"
            )
            logger.warning("   ‚Üí Message repouss√© dans queue (attente 5s)")
            
            # Attendre et repousser
            await asyncio.sleep(5)
            await self.redis_client.rpush('bot_messages', json.dumps(event_data))
            return  # STOP - un autre worker s'en occupe
        
        logger.info(f"‚úÖ Lock Redis acquis pour {match_id[:8]}")
        
        # ============================================
        # TRAITEMENT AVEC LOCK (toujours lib√©r√©)
        # ============================================
        
        try:
            await self._process_message_impl(event_data)
            
        except Exception as e:
            logger.error(f"‚ùå Erreur traitement: {e}", exc_info=True)
            
            # Cleanup cache en cas d'erreur
            try:
                if self.response_cache:
                    await self.response_cache.clear_generating(match_id)
                    logger.info("üßπ Cache g√©n√©ration cleared (erreur)")
            except Exception as cache_err:
                logger.error(f"‚ùå Erreur clear cache: {cache_err}")
                
        finally:
            # ============================================
            # üîí TOUJOURS LIB√âRER LE LOCK REDIS
            # ============================================
            
            # üîß SAFETY: Clear cache g√©n√©ration (au cas o√π)
            try:
                if hasattr(self, 'response_cache') and self.response_cache:
                    # V√©rifier si toujours en g√©n√©ration
                    is_gen = await self.response_cache.is_generating(match_id)
                    if is_gen:
                        await self.response_cache.clear_generating(match_id)
                        logger.warning("‚ö†Ô∏è Cache g√©n√©ration still set, cleared (finally)")
            except Exception as safety_err:
                logger.error(f"‚ùå Safety clear cache failed: {safety_err}")
            
            await self.conversation_lock.release(match_id)
            logger.info(f"üîì Lock Redis lib√©r√© pour {match_id[:8]}")
    
    async def _process_message_impl(self, event_data: dict):
        """
        ‚úÖ VERSION 3.0 - Impl√©mentation avec monitoring continu
        
        Surveille les nouveaux messages pendant TOUTE la dur√©e:
        - R√©flexion (thinking delay)
        - Frappe (typing simulation)
        
        Annule et repousse si nouveaux messages d√©tect√©s.
        """
        # Extraction donn√©es
        if event_data.get('type') == 'grouped':
            messages = event_data['messages']
            match_id = event_data['match_id']
            bot_id = event_data['bot_id']
            main_msg = messages[-1]
            user_id = main_msg['sender_id']
            user_message = ' '.join([m['message_content'] for m in messages])
            logger.info(f"üì¶ Traitement {len(messages)} messages group√©s")
        else:
            match_id = event_data['match_id']
            bot_id = event_data['bot_id']
            user_id = event_data['sender_id']
            user_message = event_data['message_content']
        
        logger.info("=" * 60)
        logger.info(f"ü§ñ TRAITEMENT MESSAGE INTELLIGENT")
        logger.info(f"   Match: {match_id}")
        logger.info(f"   Message: {user_message[:100]}")
        logger.info("=" * 60)
        
        # =============================
        # üÜï PHASE -1: V√âRIF DISPONIBILIT√â BOT (NOUVEAU)
        # =============================
        logger.info("\n‚è∞ Phase -1: V√©rification disponibilit√© bot...")
        
        is_available, reason = await self.availability_checker.is_bot_available(bot_id)
        
        if not is_available:
            logger.warning(f"‚è∞ Bot {bot_id[:8]} indisponible: {reason}")
            
            # Calculer prochain horaire disponible
            next_available = await self.availability_checker.get_next_available_time(bot_id)
            
            if next_available:
                # Scheduler le message pour plus tard
                await self._schedule_message_for_later(
                    event_data=event_data,
                    match_id=match_id,
                    bot_id=bot_id,
                    user_id=user_id,
                    scheduled_for=next_available
                )
                
                logger.info(f"üìÖ Message schedul√© pour {next_available.strftime('%Y-%m-%d %H:%M')}")
                logger.info("‚úÖ Traitement report√© au r√©veil du bot")
            else:
                logger.error(f"‚ùå Impossible de calculer prochain horaire pour {bot_id[:8]}")
            
            # Cleanup et stop
            await self.response_cache.clear_generating(match_id)
            return  # STOP - bot indisponible
        
        logger.info(f"‚úÖ Bot {bot_id[:8]} disponible, traitement imm√©diat")
        
        # =============================
        # PHASE 0: D√âTECTION URGENCE (NOUVEAU)
        # =============================
        logger.info("\nüö® Phase 0: D√©tection messages sans r√©ponse...")
        
        # Charger historique pr√©liminaire pour analyse urgence
        prelim_history = await self.pre_processor.fetch_conversation_history(match_id)
        
        # Analyser si r√©ponse urgente n√©cessaire
        urgency_check = await self.unanswered_detector.needs_urgent_response(
            prelim_history
            # üîß bot_id n'est plus n√©cessaire (d√©tection via is_bot)
        )
        
        force_response = False
        
        if urgency_check['urgent']:
            logger.warning("‚ö†Ô∏è R√âPONSE URGENTE N√âCESSAIRE!")
            logger.warning(f"   {urgency_check['consecutive_user_messages']} messages user cons√©cutifs")
            logger.warning(f"   Context: {urgency_check['context']}")
            logger.warning(f"   Attente: {urgency_check['minutes_waiting']:.1f} minutes")
            
            force_response = True
            logger.info("üö® Force response activ√© ‚Üí Ignore cache")
        
        # =============================
        # PHASE 0bis: CHECK CACHE (g√©n√©ration en cours)
        # =============================
        
        if not force_response:
            logger.info("\nüíæ Phase 0bis: V√©rification cache...")
            
            if await self.response_cache.is_generating(match_id):
                logger.warning("‚ö†Ô∏è G√©n√©ration d√©j√† en cours (cache)")
                logger.warning("   ‚Üí SKIP")
                return
            
            logger.info("‚úÖ Pas de g√©n√©ration en cours")
        else:
            logger.info("‚ö†Ô∏è Cache ignor√© (force_response)")
        
        # Marquer g√©n√©ration en cours
        await self.response_cache.mark_generating(match_id, user_message)
        
        # =============================
        # PHASE 1: PRE-PROCESSING
        # =============================
        logger.info("\nüì¶ Phase 1: Pre-processing...")
        
        context = await self.pre_processor.prepare_context(
            match_id, bot_id, user_id
        )
        
        if context['is_typing']:
            logger.info("‚ö†Ô∏è User tape encore ‚Üí ABANDON")
            
            # üîß Clear cache avant de repousser
            await self.response_cache.clear_generating(match_id)
            logger.info("üßπ Cache g√©n√©ration cleared (user typing)")
            
            await asyncio.sleep(5)
            event_data['retry_count'] = event_data.get('retry_count', 0) + 1
            
            if event_data['retry_count'] <= 5:
                await self.redis_client.rpush('bot_messages', json.dumps(event_data))
                logger.info(f"üì® Repouss√© (retry {event_data['retry_count']}/5)")
            else:
                logger.warning("‚ùå Trop de retry, abandon")
            
            return
        
        # =============================
        # PHASE 1.5: V√âRIFICATION LIMITE/EXIT (NOUVEAU)
        # =============================
        logger.info("\nüö® Phase 1.5: V√©rification limite bot...")
        
        match_info = await self.supabase.fetch_one(
            """
            SELECT bot_messages_count, bot_messages_limit, bot_exit_reason
            FROM matches
            WHERE id = $1
            """,
            match_id
        )
        
        if not match_info:
            logger.error(f"‚ùå Match {match_id} non trouv√©")
            await self.response_cache.clear_generating(match_id)
            return
        
        count = match_info['bot_messages_count'] or 0
        limit = match_info['bot_messages_limit'] or 25
        exit_reason = match_info['bot_exit_reason']
        
        logger.info(f"   üìä Messages bot: {count}/{limit}")
        logger.info(f"   üö™ Exit reason: {exit_reason or 'N/A'}")
        
        # Check si d√©j√† en exit
        if exit_reason:
            logger.warning(f"   ‚ö†Ô∏è Bot d√©j√† en exit: {exit_reason}")
            logger.warning("   ‚ùå SKIP g√©n√©ration (conversation termin√©e)")
            await self.response_cache.clear_generating(match_id)
            return
        
        # Check si limite atteinte
        if count >= limit:
            logger.warning(f"   ‚ö†Ô∏è Limite atteinte: {count}/{limit}")
            logger.warning("   üö™ G√©n√©ration message d'exit au lieu de r√©ponse normale")
            
            # G√©n√©rer exit imm√©diatement
            should_exit, reason = await self.exit_manager.check_should_exit(
                match_id,
                self.supabase
            )
            
            if should_exit:
                logger.info(f"   üìù Exit confirm√©: {reason}")
                
                exit_messages = self.exit_manager.generate_exit_sequence(reason)
                
                logger.info(f"\nüì§ Envoi s√©quence exit ({len(exit_messages)} messages)...")
                
                for i, exit_msg in enumerate(exit_messages, 1):
                    delay = exit_msg['delay']
                    logger.info(f"   ‚è≥ Attente {delay}s avant msg {i}...")
                    await asyncio.sleep(delay)
                    
                    await self.activate_typing(bot_id, match_id)
                    
                    typing_time = timing_engine.calculate_typing_time(exit_msg['text'])
                    logger.info(f"   ‚å®Ô∏è Frappe {typing_time}s: {exit_msg['text'][:50]}...")
                    await asyncio.sleep(typing_time)
                    
                    await self.send_message(match_id, bot_id, exit_msg['text'])
                    logger.info(f"   ‚úÖ Exit message {i} envoy√©")
                    
                    await self.deactivate_typing(bot_id, match_id)
                
                await self.exit_manager.mark_as_exited(match_id, reason, self.supabase)
                
                logger.info("   üéØ Bot a quitt√© la conversation (limite atteinte)")
            
            # Cleanup et stop
            await self.response_cache.clear_generating(match_id)
            return
        
        logger.info("   ‚úÖ Limite OK, g√©n√©ration autoris√©e")
        
        # =============================
        # PHASE 2: ANALYSE
        # =============================
        logger.info("\nüß† Phase 2: Analyse contextuelle...")
        
        analysis = message_analyzer.analyze_message(
            user_message,
            context['history'],
            context['memory']
        )
        
        logger.info(f"   Urgency: {analysis['urgency']}/5")
        logger.info(f"   Complexity: {analysis['complexity']}/5")
        logger.info(f"   Tone: {analysis['emotional_tone']}")
        logger.info(f"   Multi-messages: {analysis['requires_multi_messages']}")
        
        # =============================
        # üÜï D√âMARRAGE MONITORING CONTINU
        # =============================
        
        base_message_count = len(context['history'])
        logger.info(f"\nüëÅÔ∏è  D√©marrage monitoring continu (base: {base_message_count})")
        
        await self.continuous_monitor.start(
            match_id=match_id,
            base_message_count=base_message_count,
            check_interval=2.0  # V√©rifier toutes les 2 secondes
        )
        
        # =============================
        # PHASE 3: TIMING - R√âFLEXION
        # =============================
        logger.info("\n‚è±Ô∏è  Phase 3: Calcul timing...")
        
        thinking_delay = timing_engine.calculate_thinking_delay(
            analysis,
            len(user_message),
            context['time_since_last_bot_minutes'] * 60
        )
        
        logger.info(f"   D√©lai r√©flexion: {thinking_delay}s")
        logger.info(f"‚è≥ Attente {thinking_delay}s (temps de r√©flexion)...")
        
        # Attendre PENDANT QUE le monitoring tourne en background
        await asyncio.sleep(thinking_delay)
        
        # ============================================
        # üÜï CHECKPOINT 1: Nouveaux messages pendant r√©flexion ?
        # ============================================
        
        if self.continuous_monitor.has_new_messages():
            logger.warning("‚ö†Ô∏è Nouveaux messages pendant r√©flexion ‚Üí ANNULATION")
            logger.info("üì® Message repouss√© pour retraitement complet")
            
            # Arr√™ter monitoring
            await self.continuous_monitor.stop()
            
            # üîß CRITICAL: Clear cache g√©n√©ration
            await self.response_cache.clear_generating(match_id)
            logger.info("üßπ Cache g√©n√©ration cleared (annulation)")
            
            # Repousser
            await asyncio.sleep(3)
            event_data['retry_count'] = event_data.get('retry_count', 0) + 1
            if event_data['retry_count'] <= 5:
                await self.redis_client.rpush('bot_messages', json.dumps(event_data))
            else:
                logger.warning("‚ùå Trop de retry")
            
            return  # STOP
        
        logger.info("‚úÖ Pas de nouveaux messages pendant r√©flexion")
        
        # =============================
        # PHASE 4: ACTIVATION TYPING
        # =============================
        logger.info("\n‚å®Ô∏è  Phase 4: Activation typing...")
        await self.activate_typing(bot_id, match_id)
        
        # =============================
        # PHASE 5: G√âN√âRATION R√âPONSE
        # =============================
        logger.info("\nüß† Phase 5: G√©n√©ration r√©ponse IA...")
        
        # üÜï Enrichir prompt si USER_CONFUSED
        clarification_context = None
        if urgency_check.get('urgent') and urgency_check['context'] == 'USER_CONFUSED':
            clarification_context = {
                'last_bot_message': [m for m in context['history'] if m.get('profiles', {}).get('id') == bot_id][-1]['content'] if any(m.get('profiles', {}).get('id') == bot_id for m in context['history']) else None,
                'confused_messages': [m['content'] for m in context['history'][-3:] if m.get('profiles', {}).get('id') != bot_id]
            }
            logger.info(f"üí° Ajout contexte clarification: {clarification_context}")
        
        prompt = prompt_builder.build_full_prompt(
            context['bot_profile'],
            context['memory'],
            context['history'],
            user_message,
            analysis,
            clarification_context=clarification_context
        )
        
        response = self.generate_response(
            prompt,
            context['bot_profile'].get('temperature', 0.8)
        )
        
        logger.info(f"‚úÖ R√©ponse: {response[:100]}...")
        
        # Check doublon apr√®s g√©n√©ration
        is_duplicate = await self.response_cache.is_duplicate_response(
            match_id,
            response
        )
        
        if is_duplicate:
            logger.error("‚ùå R√©ponse est un DOUBLON!")
            await self.response_cache.clear_generating(match_id)
            await self.continuous_monitor.stop()
            await self.deactivate_typing(bot_id, match_id)
            return
        
        # ============================================
        # üÜï CHECKPOINT 2: Nouveaux messages apr√®s g√©n√©ration ?
        # ============================================
        
        if self.continuous_monitor.has_new_messages():
            logger.warning("‚ö†Ô∏è Nouveaux messages apr√®s g√©n√©ration ‚Üí ANNULATION")
            logger.info("üì® Message repouss√©")
            
            await self.continuous_monitor.stop()
            await self.deactivate_typing(bot_id, match_id)
            
            # üîß CRITICAL: Clear cache g√©n√©ration
            await self.response_cache.clear_generating(match_id)
            logger.info("üßπ Cache g√©n√©ration cleared (annulation)")
            
            await asyncio.sleep(3)
            event_data['retry_count'] = event_data.get('retry_count', 0) + 1
            if event_data['retry_count'] <= 5:
                await self.redis_client.rpush('bot_messages', json.dumps(event_data))
            else:
                logger.warning("‚ùå Trop de retry")
            
            return  # STOP
        
        logger.info("‚úÖ Pas de nouveaux messages, on peut envoyer")
        
        # Parser messages (force un seul pour √©viter contradictions)
        messages_to_send = [response.replace('|||', ' ')]
        logger.info("   ‚û°Ô∏è Un seul message (split d√©sactiv√©)")
        
        # =============================
        # PHASE 6: ENVOI AVEC MONITORING CONTINU
        # =============================
        logger.info(f"\nüì§ Phase 6: Envoi {len(messages_to_send)} message(s)...")
        
        # Stocker dans cache avant envoi
        await self.response_cache.store_response(
            match_id,
            response,
            user_message
        )
        
        for i, msg in enumerate(messages_to_send):
            # ============================================
            # üÜï V√âRIFIER AVANT CHAQUE MESSAGE
            # ============================================
            
            if self.continuous_monitor.has_new_messages():
                logger.warning(f"‚ö†Ô∏è Nouveaux messages avant msg {i+1} ‚Üí ANNULATION")
                await self.continuous_monitor.stop()
                await self.deactivate_typing(bot_id, match_id)
                
                # üîß CRITICAL: Clear cache g√©n√©ration
                await self.response_cache.clear_generating(match_id)
                logger.info("üßπ Cache g√©n√©ration cleared (annulation)")
                
                # Repousser
                await asyncio.sleep(3)
                event_data['retry_count'] = event_data.get('retry_count', 0) + 1
                if event_data['retry_count'] <= 5:
                    await self.redis_client.rpush('bot_messages', json.dumps(event_data))
                
                return  # STOP
            
            # Calculer temps frappe
            typing_time = timing_engine.calculate_typing_time(msg)
            logger.info(f"   ‚è±Ô∏è Frappe msg {i+1}: {typing_time}s")
            
            # ============================================
            # üÜï ATTENDRE PENDANT QUE MONITORING TOURNE
            # ============================================
            await asyncio.sleep(typing_time)
            
            # ============================================
            # üÜï V√âRIFIER JUSTE AVANT ENVOI
            # ============================================
            
            if self.continuous_monitor.has_new_messages():
                logger.warning(f"‚ö†Ô∏è Nouveaux messages juste avant envoi ‚Üí ANNULATION")
                await self.continuous_monitor.stop()
                await self.deactivate_typing(bot_id, match_id)
                
                # üîß CRITICAL: Clear cache g√©n√©ration
                await self.response_cache.clear_generating(match_id)
                logger.info("üßπ Cache g√©n√©ration cleared (annulation)")
                
                await asyncio.sleep(3)
                event_data['retry_count'] = event_data.get('retry_count', 0) + 1
                if event_data['retry_count'] <= 5:
                    await self.redis_client.rpush('bot_messages', json.dumps(event_data))
                
                return  # STOP
            
            # Envoyer
            await self.send_message(match_id, bot_id, msg)
            
            # D√©sactiver typing
            await self.deactivate_typing(bot_id, match_id)
            
            # Pause entre messages si plusieurs
            if i < len(messages_to_send) - 1:
                pause = timing_engine.calculate_pause_between_messages(len(msg))
                logger.info(f"   ‚è∏Ô∏è Pause: {pause}s")
                await asyncio.sleep(pause)
                await self.activate_typing(bot_id, match_id)
        
        # ============================================
        # üÜï ARR√äTER MONITORING
        # ============================================
        
        await self.continuous_monitor.stop()
        
        logger.info("\n‚úÖ Message trait√© avec succ√®s !")
        
        # Cleanup cache
        await self.response_cache.clear_generating(match_id)
        
        # =============================
        # PHASE 7: V√âRIFICATION EXIT
        # =============================
        logger.info("\nüö™ Phase 7: V√©rification exit...")
        
        should_exit, exit_reason = await self.exit_manager.check_should_exit(
            match_id, 
            self.supabase
        )
        
        if should_exit:
            logger.info(f"   ‚ö†Ô∏è Bot doit quitter: {exit_reason}")
            
            exit_messages = self.exit_manager.generate_exit_sequence(exit_reason)
            
            logger.info(f"\nüì§ Envoi s√©quence exit ({len(exit_messages)} messages)...")
            
            for i, exit_msg in enumerate(exit_messages, 1):
                delay = exit_msg['delay']
                logger.info(f"   ‚è≥ Attente {delay}s avant msg {i}...")
                await asyncio.sleep(delay)
                
                await self.activate_typing(bot_id, match_id)
                
                typing_time = timing_engine.calculate_typing_time(exit_msg['text'])
                logger.info(f"   ‚å®Ô∏è Frappe {typing_time}s: {exit_msg['text'][:50]}...")
                await asyncio.sleep(typing_time)
                
                await self.send_message(match_id, bot_id, exit_msg['text'])
                logger.info(f"   ‚úÖ Exit message {i} envoy√©")
                
                await self.deactivate_typing(bot_id, match_id)
            
            await self.exit_manager.mark_as_exited(match_id, exit_reason, self.supabase)
            
            logger.info("   üéØ Bot a quitt√© la conversation")
        else:
            logger.info("   ‚úÖ Pas d'exit pour ce message")
    
    async def close(self):
        """
        M√©thode unifi√©e pour fermer toutes les connexions.
        Utilis√©e par scheduled_processor.
        """
        if self.redis_client:
            await self.redis_client.aclose()
        if self.supabase:
            await self.supabase.close()
    
    async def _schedule_message_for_later(
        self,
        event_data: dict,
        match_id: str,
        bot_id: str,
        user_id: str,
        scheduled_for: datetime
    ):
        """
        Schedule un message pour traitement ult√©rieur.
        Ins√®re dans bot_message_queue avec statut 'pending' et scheduled_for.
        """
        try:
            # R√©cup√©rer message_id depuis event_data
            message_id = event_data.get('message_id')
            
            if not message_id:
                logger.error("‚ùå message_id manquant dans event_data, impossible de scheduler")
                return
            
            # Ins√©rer dans bot_message_queue
            query = """
                INSERT INTO bot_message_queue (
                    message_id,
                    match_id,
                    bot_id,
                    sender_id,
                    status,
                    scheduled_for,
                    attempts,
                    max_attempts
                ) VALUES ($1, $2, $3, $4, 'pending', $5, 0, 3)
                ON CONFLICT (message_id) 
                DO UPDATE SET
                    status = 'pending',
                    scheduled_for = EXCLUDED.scheduled_for,
                    attempts = 0
            """
            
            await self.supabase.execute(
                query,
                message_id,
                match_id,
                bot_id,
                user_id,
                scheduled_for
            )
            
            logger.info(f"‚úÖ Message {message_id[:8]} schedul√© dans bot_message_queue")
        
        except Exception as e:
            logger.error(f"‚ùå Erreur _schedule_message_for_later: {e}", exc_info=True)
    
    async def run(self):
        """Lance le worker"""
        try:
            # Connexions
            await self.connect_supabase()
            await self.connect_redis()
            self.connect_openai()
            
            logger.info("=" * 60)
            logger.info("üß† WORKER INTELLIGENCE V3.0 ACTIF")
            logger.info("   ‚úÖ Lock Redis distribu√©")
            logger.info("   ‚úÖ Monitoring continu")
            logger.info("=" * 60)
            logger.info("üëÇ √âcoute queue 'bot_messages'...")
            logger.info("‚è≥ En attente...")
            
            # Boucle de traitement
            while True:
                result = await self.redis_client.blpop('bot_messages', timeout=1)
                
                if result:
                    queue_name, message_json = result
                    event_data = json.loads(message_json)
                    
                    # Traiter
                    await self.process_message(event_data)
                    
        except KeyboardInterrupt:
            logger.info("\n‚ö†Ô∏è  Interruption utilisateur")
        except Exception as e:
            logger.error(f"‚ùå Erreur fatale: {e}", exc_info=True)
        finally:
            logger.info("üõë Arr√™t du worker...")
            if self.redis_client:
                await self.redis_client.aclose()
            if self.supabase:
                await self.supabase.close()


async def main():
    """Point d'entr√©e"""
    worker = WorkerIntelligence()
    await worker.run()


if __name__ == "__main__":
    asyncio.run(main())
