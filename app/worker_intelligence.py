"""
Worker Intelligence - Traite les messages avec intelligence conversationnelle

- Pre-processing (typing, history, memory)
- Analyse contextuelle
- Timing adaptatif
- G√©n√©ration r√©ponse
- Update memory
"""

import asyncio
import json
import logging
from datetime import datetime
from supabase import create_client, Client, ClientOptions
import redis.asyncio as redis
from openai import OpenAI

from app.config import settings
from app.pre_processing import PreProcessor
from app.analysis import message_analyzer
from app.utils.timing import timing_engine

logging.basicConfig(
    level=getattr(logging, settings.log_level),
    format='%(asctime)s - %(levelname)s - %(name)s - %(message)s'
)
logger = logging.getLogger(__name__)


class WorkerIntelligence:
    """Worker intelligent avec analyse contextuelle compl√®te"""
    
    def __init__(self):
        self.supabase: Client = None
        self.redis_client = None
        self.openai_client = None
        self.pre_processor = None
        
    async def connect_supabase(self):
        """Connexion Supabase"""
        logger.info("üîå Connexion √† Supabase...")
        
        options = ClientOptions(
            headers={
                "apikey": settings.supabase_service_key,
                "Authorization": f"Bearer {settings.supabase_service_key}"
            }
        )
        
        self.supabase = create_client(
            settings.supabase_url,
            settings.supabase_service_key,
            options=options
        )
        self.pre_processor = PreProcessor(self.supabase)
        logger.info("‚úÖ Connect√© √† Supabase")
        
    async def connect_redis(self):
        """Connexion Redis"""
        logger.info("üîå Connexion √† Redis...")
        self.redis_client = await redis.from_url(
            settings.redis_url,
            encoding="utf-8",
            decode_responses=True
        )
        logger.info("‚úÖ Connect√© √† Redis")
    
    def connect_openai(self):
        """Connexion OpenRouter"""
        logger.info("üîå Connexion √† OpenRouter...")
        self.openai_client = OpenAI(
            base_url=settings.openrouter_base_url,
            api_key=settings.openrouter_api_key
        )
        logger.info("‚úÖ Connect√© √† OpenRouter")
    
    def build_prompt(
        self,
        bot_profile: dict,
        memory: dict,
        history: list,
        current_message: str,
        analysis: dict
    ) -> str:
        """Construit un prompt enrichi avec full context"""
        system_prompt = bot_profile.get('system_prompt', '')
        
        # M√©moire long-terme
        memory_context = f"""
M√âMOIRE DE CETTE PERSONNE:
- Nom: {memory.get('user_name', 'inconnu')}
- Niveau relation: {memory.get('relationship_level', 'stranger')}
- Trust score: {memory.get('trust_score', 0)}/100
- Ton conversation: {memory.get('conversation_tone', 'neutral')}
- Topics pr√©f√©r√©s: {', '.join(memory.get('preferred_topics', [])) or 'aucun'}
- Topics √† √©viter: {', '.join(memory.get('topics_to_avoid', [])) or 'aucun'}
"""
        
        # Historique (derniers 30 messages max pour prompt)
        history_context = "\n".join([
            f"{msg['sender_name']}: {msg['content']}"
            for msg in history[-30:]
        ])
        
        # Analysis
        analysis_context = f"""
ANALYSE DU MESSAGE:
- Urgence: {analysis['urgency']}/5
- Complexit√©: {analysis['complexity']}/5
- Ton √©motionnel: {analysis['emotional_tone']}
- Type: {analysis['message_type']}
"""
        
        # Instructions adaptatives
        instructions = "INSTRUCTIONS:\n"
        
        if analysis['urgency'] >= 4:
            instructions += "- R√©ponds rapidement et directement\n"
        
        if analysis['requires_multi_messages']:
            instructions += "- D√©coupe ta r√©ponse en 2-3 messages courts et naturels\n"
            instructions += "- Format: message1|||message2|||message3 (s√©par√©s par |||)\n"
        else:
            instructions += "- Un seul message naturel suffit\n"
        
        if memory.get('trust_score', 0) >= 70:
            instructions += "- Relation √©tablie, sois plus authentique et intime\n"
        else:
            instructions += "- Relation naissante, reste naturel mais l√©ger\n"
        
        # Assembler
        full_prompt = f"""{system_prompt}

{memory_context}

HISTORIQUE CONVERSATION:
{history_context}

{analysis_context}

{instructions}

MESSAGE ACTUEL:
{current_message}

TA R√âPONSE:"""
        
        return full_prompt
    
    def generate_response(self, prompt: str, temperature: float = 0.8) -> str:
        """G√©n√®re une r√©ponse avec Grok"""
        try:
            response = self.openai_client.chat.completions.create(
                model=settings.openrouter_model,
                messages=[
                    {"role": "user", "content": prompt}
                ],
                temperature=temperature,
                max_tokens=500
            )
            
            return response.choices[0].message.content.strip()
            
        except Exception as e:
            logger.error(f"‚ùå Erreur g√©n√©ration: {e}")
            return "D√©sol√©, j'ai un petit bug technique üòÖ"
    
    async def activate_typing(self, bot_id: str, match_id: str):
        """Active l'indicateur de frappe"""
        try:
            self.supabase.table('typing_events').upsert({
                'user_id': bot_id,
                'match_id': match_id,
                'is_typing': True,
                'started_at': datetime.now().isoformat()
            }).execute()
        except Exception as e:
            logger.error(f"‚ùå Erreur activate typing: {e}")
    
    async def deactivate_typing(self, bot_id: str, match_id: str):
        """D√©sactive l'indicateur de frappe"""
        try:
            self.supabase.table('typing_events').upsert({
                'user_id': bot_id,
                'match_id': match_id,
                'is_typing': False,
                'updated_at': datetime.now().isoformat()
            }).execute()
        except Exception as e:
            logger.error(f"‚ùå Erreur deactivate typing: {e}")
    
    async def send_message(self, match_id: str, bot_id: str, content: str):
        """Envoie un message"""
        try:
            self.supabase.table('messages').insert({
                'match_id': match_id,
                'sender_id': bot_id,
                'content': content,
                'type': 'text',
                'status': 'sent'
            }).execute()
            
            logger.info(f"‚úÖ Message envoy√©: {content[:50]}...")
            
        except Exception as e:
            logger.error(f"‚ùå Erreur envoi message: {e}")
            raise
    
    async def process_message(self, event_data: dict):
        """
        Traite un message avec intelligence compl√®te
        """
        try:
            # Extraction donn√©es
            if event_data.get('type') == 'grouped':
                # Messages group√©s
                messages = event_data['messages']
                match_id = event_data['match_id']
                bot_id = event_data['bot_id']
                # Prendre le dernier message comme principal
                main_msg = messages[-1]
                user_id = main_msg['sender_id']
                user_message = ' '.join([m['message_content'] for m in messages])
                logger.info(f"üì¶ Traitement {len(messages)} messages group√©s")
            else:
                # Message simple
                match_id = event_data['match_id']
                bot_id = event_data['bot_id']
                user_id = event_data['sender_id']
                user_message = event_data['message_content']
            
            logger.info("=" * 60)
            logger.info(f"ü§ñ TRAITEMENT MESSAGE INTELLIGENT")
            logger.info(f"   Match: {match_id}")
            logger.info(f"   Message: {user_message[:100]}")
            logger.info("=" * 60)
            
            # =============================
            # PHASE 1: PRE-PROCESSING
            # =============================
            logger.info("\nüì¶ Phase 1: Pre-processing...")
            
            should_wait, context = await self.pre_processor.prepare_context(
                match_id, bot_id, user_id
            )
            
            if should_wait:
                # User tape encore, repousser le job
                logger.info("‚è∏Ô∏è  User tape, on repousse le job...")
                await asyncio.sleep(2)
                await self.redis_client.rpush('bot_messages', json.dumps(event_data))
                return
            
            # =============================
            # PHASE 2: ANALYSE
            # =============================
            logger.info("\nüß† Phase 2: Analyse contextuelle...")
            
            analysis = message_analyzer.analyze_message(
                user_message,
                context['history'],
                context['memory']
            )
            
            logger.info(f"   Urgency: {analysis['urgency']}/5")
            logger.info(f"   Complexity: {analysis['complexity']}/5")
            logger.info(f"   Tone: {analysis['emotional_tone']}")
            logger.info(f"   Multi-messages: {analysis['requires_multi_messages']}")
            
            # =============================
            # PHASE 3: TIMING - R√âFLEXION
            # =============================
            logger.info("\n‚è±Ô∏è  Phase 3: Calcul timing...")
            
            thinking_delay = timing_engine.calculate_thinking_delay(
                analysis,
                len(user_message),
                context['time_since_last_bot_minutes'] * 60  # Convertir en secondes
            )
            
            logger.info(f"   D√©lai r√©flexion: {thinking_delay}s")
            logger.info(f"‚è≥ Attente {thinking_delay}s (temps de r√©flexion)...")
            await asyncio.sleep(thinking_delay)
            
            # =============================
            # PHASE 4: ACTIVATION TYPING
            # =============================
            logger.info("\n‚å®Ô∏è  Phase 4: Activation typing...")
            await self.activate_typing(bot_id, match_id)
            
            # =============================
            # PHASE 5: G√âN√âRATION R√âPONSE
            # =============================
            logger.info("\nüß† Phase 5: G√©n√©ration r√©ponse IA...")
            
            prompt = self.build_prompt(
                context['bot_profile'],
                context['memory'],
                context['history'],
                user_message,
                analysis
            )
            
            response = self.generate_response(
                prompt,
                context['bot_profile'].get('temperature', 0.8)
            )
            
            logger.info(f"‚úÖ R√©ponse: {response[:100]}...")
            
            # Parser multi-messages si n√©cessaire
            if '|||' in response:
                messages_to_send = [m.strip() for m in response.split('|||')]
            else:
                messages_to_send = [response]
            
            # =============================
            # PHASE 6: ENVOI AVEC TIMING
            # =============================
            logger.info(f"\nüì§ Phase 6: Envoi {len(messages_to_send)} message(s)...")
            
            for i, msg in enumerate(messages_to_send):
                # Calculer temps frappe
                typing_time = timing_engine.calculate_typing_time(msg)
                logger.info(f"   Message {i+1}: {typing_time}s de frappe")
                
                await asyncio.sleep(typing_time)
                
                # Envoyer
                await self.send_message(match_id, bot_id, msg)
                
                # D√©sactiver typing temporairement
                await self.deactivate_typing(bot_id, match_id)
                
                # Pause entre messages si plusieurs
                if i < len(messages_to_send) - 1:
                    pause = timing_engine.calculate_pause_between_messages(len(msg))
                    logger.info(f"   Pause: {pause}s")
                    await asyncio.sleep(pause)
                    
                    # R√©activer typing pour prochain
                    await self.activate_typing(bot_id, match_id)
            
            logger.info("\n‚úÖ Message trait√© avec succ√®s !")
            
        except Exception as e:
            logger.error(f"‚ùå Erreur traitement: {e}", exc_info=True)
    
    async def run(self):
        """Lance le worker"""
        try:
            # Connexions
            await self.connect_supabase()
            await self.connect_redis()
            self.connect_openai()
            
            logger.info("=" * 60)
            logger.info("üß† WORKER INTELLIGENCE ACTIF")
            logger.info("=" * 60)
            logger.info("üëÇ √âcoute queue 'bot_messages'...")
            logger.info("‚è≥ En attente...")
            
            # Boucle de traitement
            while True:
                result = await self.redis_client.blpop('bot_messages', timeout=1)
                
                if result:
                    queue_name, message_json = result
                    event_data = json.loads(message_json)
                    
                    # Traiter
                    await self.process_message(event_data)
                    
        except KeyboardInterrupt:
            logger.info("\n‚ö†Ô∏è  Interruption utilisateur")
        except Exception as e:
            logger.error(f"‚ùå Erreur fatale: {e}", exc_info=True)
        finally:
            logger.info("üõë Arr√™t du worker...")
            if self.redis_client:
                await self.redis_client.aclose()


async def main():
    """Point d'entr√©e"""
    worker = WorkerIntelligence()
    await worker.run()


if __name__ == "__main__":
    asyncio.run(main())
